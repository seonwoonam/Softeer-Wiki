# 2025-01-20 리뷰 및 회고

## 리뷰

### 수업
#### Apache Hadoop
- 각각의 일들을 완벽히 분리
- HDFS의 목표 및 가정
    - Hardware Failure 발생해도 괜찮다.
    - Streaming Data
    - Moving Computation is Cheaper than Moving Data
        - Computation을 옮기는게 데이터를 옮기는 것보다 저렴하다
        - 전제조건 : 데이터가 쪼개져있어야 한다.(분산되어 저장되어 있다라는 전제가 있음)
        - 데이터를 불러와서 합치고 뭐하는 비용이 비싸다.
        - 연산하는 application을 데이터로 보내서 처리
        - 데이터 특성이 parallism해야 하둡 성격에 맞음
            - 나눠서 처리해서 합쳐도, 합쳐서 처리한 거랑 같다.
    - Data Locality라는 전제가 매우 중요하다!
    - 똑같은 하드웨어, 소프트웨어가 있다(heterogenous : 어떤 거에 뭐 주고 이런거를 생각할 필요 없게함)
- 4개의 모듈
    - Hadoop Common
    - HDFS (파일 시스템) - NameNode, DataNode
    - Hadoop Yarn (리소스 관리) - Resource Manager, Load Manager
    - Hadoop MapReduce (어플리케이션 레이어)
- Hadoop Architecture
    - Master, Slave 구조들로 되어있음
    - 각각의 레이어 별로 Master, Slave가 따로따로 있음
- Simple Coherency Model
    - 어떤 목적을 이루기 위해 다른 것은 버린다.
- WORM(write-once-read-many)
    - 장점 : 비용이 싸다(Lock 같은 거 신경 안써도 됨), 많은 양의 데이터를 빠르게 처리가능, high throughoutput
    - 단점 : 새로운 데이터(업데이트 해야하는)에 약하다, 용량이 커진다.
- Commodity Hardware
    - 큰 돈 들이지 않는 하드웨어(저렴한 하드웨어)
- Rack
    - 물리적으로 switching hub가 관리하는 덩이리
- Name Node
    - 파일 시스템의 metadata를 저장하고 관리.
    - 파일 위치, permission 등등
- Data Node
    - 실제 데이터 block을 저장
    - replication 기본 전제는 다른 데이터 노드에 복제.
- Data Locality(속도 가장 빠름) → 이걸 추구
    - 데이터랑 내가 돌리는 application이 같이 있다.
- Rack Locality
    - Rack 단위
    - 다른 application이 돌고 있을 때 사용?
- Different Rack (이거를 없애기 위해 노력해야함)
- Yarn
    - 리소스 매니저
    - 기본 컨셉 : 자원 관리와 job scheduling/monitor(ApplicationMaster의 일)를 분리
    - 하둡에게 이거하세요 하는 단위 : application
    - RM과 AM 분명히 다르다. 서로에게 관심이 없다.
    - 하드웨어 모니터링, 리소스 배정 : 리소스 매니저의 일(application의 일에는 관심이 없음)
    - 기계 관리, 자기 자신에 있는 Container 상태 관리 : NodeManager, per Machine.
    - 어플리케이션 모니터링 : AM(Application Master)의 일(내꺼만)
    - AM은 Application 돌릴 때 생성되고 끝나면 죽음.

- Master Node
    - Resource Manager
        - Node Manager에게 정보 받아서 던져줌
        - 던져주는 것만 담당.
    - Scheduler : Application Master의 실행을 담당
    - Application Manager
        - AM container 실패를 확인하고 scheduler에게 실행하라고 넘김.
- Node Manager
    - 하드웨어 모니터링 해서 resource Manager에게 던짐.
- Application Master
    - 컨테이너 모니터링 해서 resource Manager에게 던짐.

- 내가 필요한 데이터를 누가 아냐?
    - Application Master
        - 내 데이터가 어디에 있는지 찾고, 그 Node에 있는 컨테이너(데이터)를 할당해주세요 라고 요청해야함.

#### Hadoop MapReduce
- 수 천 개의 노드를 돌리려고 사용.
- 기본적으로 HDFS와 YARN 위에서 돌아가니까 혜택을 받음.
- 로컬 디스크에 씀.
- shuffle 후에는 network transfer 생김. → 극단적으로 느려짐
- Map과 shuffle을 적게하는게 유리함.
- Reduce 끝나야 HDFS에 씀.
- 데이터 양이 많아지면 이렇게 할 수 밖에 없다.


### W3M1 : 도커에 하둡을 설치해보자
- 도커에 eclipse-temurin:8-jdk-focal를 base image로 하고, 디버깅을 하며 Dockerfile을 만들어주었다. 
- 하둡을 설치하기 위해서는 자바가 필요해서 위의 이미지를 사용하였다.
- 하둡은 curl 이용하여 다운로드 받았고 실행해보았다.
- 하둡이 JAVA_HOME 환경변수를 찾지 못하는 문제가 있어서, 하둡의 env 파일에 직접 입력하는 방식으로 수정했다.
- ssh 라이브러리를 설치하고, 서비스를 시작해주어야 하둡이 실행되었다.
- 정확히 원리를 파악하지 못해서 ssh 부분을 알아봐야겠다.


## 회고
### Keep
- 아이디어를 생각하기 위해 실생활에서 내가 불편한 점이 무엇일까?를 생각하였다. 출퇴근 시간에 '지하철에서 저 앉아있는 사람은 언제 내릴까' 라는 생각을 한적 있는데 이를 바탕으로 재밌는 아이디어가 나오게 되었다. 내가 실생활에 불편함을 느끼는 것과 즐겨 하는 것에서 아이디어를 생각해봐야겠다. 

### Problem
- 아이디어를 생각해내는데 어려움이 있었다. 오랜만에 답이 정해져있거나, 정도가 있는 것이 아닌 창의적인 생각을 했어야 해서 어려웠다. 하지만 이런 창의적인 생각을 자주 해야 엔지니어로서의 경쟁력도 생긴다고 생각한다. 
- 아직 하둡이 어떻게 사용되는지 와닿지 않는다.

### Try
- 불편한 점이 생기면 아이디어로 메모해놓는 습관을 가져봐야겠다. 아이디어가 필요할 때 마다 꺼내쓰면 될 거 같다.
- 하둡 설치하고 실행하면서 해당 과정에 대해 꼼꼼히 알아보기.