# 2025-01-08 리뷰 및 회고

## 리뷰
### ETL 프로세스 구현하기
- Raw data를 저장해야 하는 이유에 대해서 생각해보았다.
    - 데이터를 어떻게 바라보느냐에 따라 데이터 type이 다르듯이 Queue의 함정에 빠지지 않기 위해서, Raw data를 저장한다고 생각한다. 
    - Extract한 데이터가 매우 클 때, Transform 전에 저장하지 않는다면 Transform 과정에서 오류가 발생하였을 때 다시 Extract를 거쳐야 하는 번거러운 과정이 있을 것 같다. 이러한 상황은 방지하기 위해 Extract 과정이 끝나면 해당 raw data를 저장하는 것 같다.
    - 해당 미션에서는 하나의 웹 사이트, 즉 하나의 소스 시스템에서 데이터를 추출하지만, 여러 소스 시스템에서 데이터를 추출할 수도 있다. 이러한 상황에서는 데이터를 뽑아 온 후 transform을 거치기 전에 모아서 저장해줘야 하는데 이러한 이유들로 raw data를 저장하는 것 같다.

- Raw 데이터 양이 압도적으로 많을 때를 대비하여 생각과 코드적으로 개선하였다.
    - 코드적으로 개선할 수 있는 부분을 생각하고 개선하였다.
    - Extract 과정에서는 request.get(url, stream=True)를 통해 response를 청크 단위로 쪼개어 메모리에 로드해, 대용량 데이터일때도 처리할 수 있도록 개선하였다.
     - 개념적으로는 판다스의 데이터 처리 방식이 eager 하게 메모리에 데이터를 올리기 때문에 빅데이터일 경우 out of memory 같은 문제가 발생하여 한계가 있다. 이로 인해 lazy한 방식으로 메모리에 데이터를 올릴 수 있는 Pyspark와 같은 도구를 활용해야 할 것 같다. 

- Raw 데이터를 Transform 하는데 시간이 아주 오래 걸릴 때 개선 방안을 생각해보았다. 
    - Transform 과정을 병렬/분산 처리를 하여 대용량의 데이터일 경우 효율적으로 처리할 수 있도록 구현하였다.
    - 파이썬의 멀티프로세싱 라이브러리인 Pool을 이용해서 병렬처리를 구현하였다. 
    - 실험 결과 단순히 해당 프로젝트에서는 데이터 row 수가 200개 밖에 되지 않았기 때문에 system call 호출 시간 등으로 인해 병렬처리를 하면 더욱 느려졌지만, 데이터 크기가 비대해 진다면 효율이 좋을 것 같다. 
   
- 위키피디아가 아닌, IMF 홈페이지를 통해 데이터를 가져오는 방법을 생각해보고, 구현하였다.
    - IMF 홈페이지에는 다양한 데이터를 다루는 API를 제공하고 있다.
    - 이를 활용하여 각 나라별 GDP, 각 Region 별 GDP를 요청하여 데이터를 얻을 수 있었다.
    - 하지만, IMF 웹사이트에서는 각 나라별로 Region을 어떤식으로 Mapping 하는지에 대한 데이터는 제공하지 않고 있어서, 데이터베이스에 각 나라별 Region을 저장할 순 없었다. 

- 데이터가 갱신되면 과거의 데이터는 어떻게 되어야 할지, 과거의 데이터를 조회할 필요가 있다면 ETL 프로세스를 어떻게 변경해야 할지 생각해보았다.
    - ETL 전체 과정을 IMF 데이터가 업데이트 되는 주기에 맞춰 ETL 과정이 이뤄지도록 구현한다. 매년 2회 자료가 제공되기 때문에 6개월 간격으로 ETL 이 진행되어 6개월 전 데이터가 저장되어 있을 경우 ETL을 진행하고, 6개월 이내의 데이터라면 이미 추출한 데이터를 보여주는 방식으로 구현한다.
    - 위 방법에서는 로그를 활용할 수 있다. 로그 상에서 6개월 이내에 데이터를 추출하였고, 그 데이터 파일명을 통해 가장 최신의 정보라면 이미 추출한 데이터를 사용하고, 가장 최신의 정보가 아니라면 ETL이 진행되어 새로운 데이터를 저장하도록 한다.


## 회고
### Keep
- Pool을 활용한 multiprocessing, 스트림 방식으로 다운로드 등을 직접 구현해보면서 멀티프로세싱 개념 및 문제상황에 대해 명확히 생각해보고 구현할 수 있었다. 직접 구현해보는 과정을 통해 개념을 확고히 할 수 있어 도움이 많이 되었다고 생각했다. 

### Problem
- 문제상황에 대해 생각해보면서 여러 자료들을 검색하고 찾아봐야 하는 경우가 많았다. 효율적으로 정보를 찾아보고 도움이 되는 정보를 색출하는 것에 어려움이 있었다. 

### Try
- 전체적인 로드맵 등을 확인하여 전반적인 시야를 넓혀 봐야겠다. 
- 문제상황에 다른사람이 대응을 해본 경험들을 읽어봐야겠다.(stackoverflow 같은 곳에서) 