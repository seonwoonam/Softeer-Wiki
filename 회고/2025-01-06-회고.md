# 2025-01-06 리뷰 및 회고

## 리뷰
### SQL 학습
- SQL 학습을 하면서 헷갈리거나 몰랐던 내용을 다시 한번 복습해볼 수 있었다.
- 조인을 여러 테이블 할 때 () 를 통해서 하는데 이는 결과는 같지만 명시적으로 좀 더 명확하게 보이게 해준다.
- 셀프조인 : 본인 테이블 내부에 있는 데이터를 가져와 쓰고 싶을 때
    - Inner join 쓰기도 한다.
    - 자기 자신 참조하는것은 피해줘야한다.
- Union 집합 합
- Union All은 중복된 것도 다 나온다.
- Exist는 subquery와 보통 함께 사용한다. 
    - WHERE EXISTS
- ANY
    - 주로 서브쿼리에서 사용하는 다중 행 연산자. 조건을 만족하는 값이 하나라도 있다면 결과 리턴
- ALL
    - 모든 조건을 만족하는 결과를 리턴
    - where문에서도 쓸 수 있지만, Select all로도 사용 가능. -> select의 기본동작이랑 똑같다. 
- SELECT INTO
    - 한 테이블에서 새로운 테이블로 정보를 복사할 때 사용한다.
    - IN 까지 사용하면 외부 데이터베이스 테이블에 데이터를 넣을 수 있다. 
- INSERT INTO SELECT
    - 하나의 테이블에 있는 데이터들을 다른 테이블로 복사하는데 사용.
- CASE
    - if문과 비슷
    - WHEN + THEN
    - ELSE
    - END AS
    - switch문과 비슷하게도 사용가능
    - select의 컬럼, where문, order by 등에서 다양히 사용 가능
- Procedure
    - 쿼리문들의 집합으로, 어떤 동작을 여러 쿼리를 거쳐 일괄적으로 처리할 때 사용.
    - 사용이유?
        - 성능 향상 -> 최적화되게 됨(메모리 캐싱)
        - 유지보수 및 재활용
        - 보안강화
        - 네트워크 부하 줄일 수 있음

### ETL 프로세스 구현하기
- ETL 프로세스 과정에 대해 공부할 수 있었다. ETL은 Extract, Transform, Load과정을 나타낸다. Extract의 경우 원천에서 raw_data를 뽑아내는 과정으로 BeautifulSoup4를 이용해서 web scaping을 진행하였다. 이 과정 속에서 select 메소드를 통해 css 선택자를 이용해서 html 태그를 찾고, sup 태그와 같은 필요없는 태그를 제거하며, 없는 데이터는 None 값을 가질 수 있도록 처리해주었다. 이러한 과정이 Extract 과정인지 헷갈리기도 하였지만 transform 하기 전 사용해야할 데이터를 준비한다라는 생각에 Extract과정이라고 생각하였다. 
- Transform 과정에서는 raw_data를 dataframe에 넣고, 이를 이용해 국가별 GDP 단위를 수정해주는 과정을 거쳤다. 
- Load 과정에서는 앞서 transform 해준 데이터를 json 형태의 파일로 추출해내는 과정을 진행하였다.
- 파이썬 logging 라이브러리를 이용하여 로그를 찍어주는 과정을 진행하였다. 이 때 addHandler라는 함수를 사용하였는데, 이를 사용할 때 마다 반복적으로 호출하여 로그가 여러개가 찍히는 오류가 발생하였다. 이로 인해 공용으로 사용하는 Logger 클래스를 만들어 이미 Handler가 생성되어 있으면 추가 되지 않도록 수정해주었다. 
- 이외의 고민거리나, 해야할 거리로는 raw_data단 부터 없는 값의 순위를 어떤 식으로 처리해주어야 할지, 지역과 나라를 어떻게 mapping해주어야 할지에 대해 고민해보고 방안을 찾아봐야겠다.

## 회고
### Keep
- 작업을 시작하기전 ETL과 같은 개념적인 부분을 공부하고, 미션을 전체적으로 파악한 후 접근하였다. 이러한 과정은 전체적인 흐름을 예상해보고, 코드를 구현할 수 있게되어 효율성과 이해도를 높여준 것 같다. 
- 코드또한 전체적으로 함수로 분리해놓고 구현을 시작하였다. 함수의 목적성을 갖고 구현할 수 있었고, 역할 및 가독성을 확실히 할 수 있게 되었다. 

### Problem
- beautifulsoup을 이용하여 html을 불러오는 과정에서 출력 데이터를 확실히 읽어보지 않아 문제의 원인을 파악하는데 시간을 많이 사용했다. 
- DataFrame 타입을 사용하지 않고 transform을 진행했었는데, DataFrame으로 할 경우 훨씬 간단하고, 가독성이 좋으며 빠르게 처리될 수 있었다. 배운 내용을 적용시키지 않았었다.

### Try
- 원하지 않는 데이터가 나왔더라도 문제 원인을 빠르게 파악하기 위해 데이터가 왜 그렇게 나오게 되는지 읽어보고 생각해봐야겠다. 
- 배운 내용을 미션에서 자주 활용할 수 있도록 노력해야겠다.