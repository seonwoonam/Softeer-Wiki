# 2025-02-03 리뷰 및 회고

## 리뷰
### 수업
Transformation
- RDD 데이터 추려라. 새로운 RDD 추가됨. 업데이트 안하기 때문에
- Narrow
    - 파티션 안에서만 데이터처리
    - 다른 파티션 결과가 나한테 상관없음
- Wide
    - 다른 파티션 결과도 알아야함.
    - shuffle이 일어나서 비용이 급증함. 줄일 수 있다면 줄여야한다.

Action
- RDD가 새롭게 생겨나는게 아님.
- Job이 만들어지고, 실행.
- Action이 실행되면 Stage의 맨 위까지 올라가서 실행시킴.

Lazy Evaluation
- transformation에서 의미.
- transformation에서는 실행하지 않고, 적어놓기만 함.
- Action이 벌어지면 그때서야 실행됨.
- spark의 optimization
    - 다 기록해놓고 몰아서 action에서 나중에 한다.
    - RDD의 낭비를 줄일 수 있음.

Partition
- smaller, logical division of data
- 어떤 node의 어떤 data
- **task와 1:1로 매칭된 데이터를 partition이라고 한다.**

Shuffle
- data skewing(비대칭 데이터)
    - 처리해줘야 하는 문제
    - group by 해봤는데, 각 그룹의 데이터 개수가 너무 차이나는 현상
    - 너무 큰 거는 다시 쪼개줘야함.

Job
- **Action 당 하나**
- **Job당 DAG 하나가 생김.(stage랑 dag 단위 다름. DAG안에 스테이지 여러개)**
- DAG는 문제를 푸는 순서를 그려놓은 거임.

### W5M1
- Spark의 RDD를 활용하여 TLC 데이터를 처리해보고, DAG를 최적화해보는 미션이다.
- 미션 진행 전에 여태까지 배운 모든 것을 사용해보고 싶었다.
- Spark, Yarn, Hdfs를 모두 사용하는 아키텍쳐를 구축하고자 하였다. 
- 이 3가지를 사용하고 도커 컨테이너로 띄우고, 클라이언트 컨테이너로 주피터를 띄우는 컨테이너를 만들었다.
- 이렇게 yarn cluster manager를 사용하고, driver는 클라이언트 단에 있는 client mode로 스파크를 실행하려고 docker container들을 구축하였다.
- 하지만 spark에서 yarn에게 요청을 보내는 부분에서 막혔다.. spark가 yarn에게 요청을 못보내고 있는거 같았다.
- 원인은 아직까지 모르겠다. 조금만 더 도전해보고 안되면 standalone mode로 해야겠다..

## 회고
### Keep
- 여태까지 배운 hdfs, yarn, spark, docker compose를 활용하여 구조를 구축해보려고 노력하였다. 각각의 역할을 되세기면서 프레임워크들을 실행시키려고 노력했고, namenode, datanode, resource manager, node manager, excutor 등을 적절한 컨테이너에서 켤 수 있었다.

### Problem
- yarn과 spark 통신부분에서 오류가 발생해 해결하지 못했다. 원인을 아직까지 모르겠다. spark에서 yarn에게 요청을 보내면 계속해서 에러가 발생하거나, 그 명령에서 멈춰버리게 되었다. 빠르게 spark 코드짜기 및 최적화를 하고 싶었지만 아키텍쳐 구성하는데 시간이 너무 오래 걸린거 같다. 

### Try
- 조금만 더 시간을 투자해보고 안되면 일단 standalone으로 실행해야겠다.