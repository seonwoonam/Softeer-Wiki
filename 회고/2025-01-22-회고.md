# 2025-01-22 리뷰 및 회고

## 리뷰

### W3M2a : 하둡 멀티노드 클러스터 만들기

<name>fs.defaultFS</name>
- 기본 파일 시스템 URI를 의미
- 데이터 노드가 네임노드를 찾는데 사용
- 모든 노드와 클라이언트가 이 주소를 통해 네임노드에 접근

- 트러블 슈팅
    - 데이터 노드와 연결이 안되었는데, 데이터노드의 ssh service를 켜주지 않아서 그랬었다.
    - 근데 하둡3 버전 이후 부터는  내부에서 만든 RPC를 사용하여 노드간에 통신을 한다는 글을 보았는데, ssh를 켜주는 이유가 궁금했다. 이 부분은 미션들이 끝나면 확인해 봐야겠다.
    - yarn에 연결이 안되었는데, yarn 설정 파일에 hostname을 추가해주는 방법으로 수정했다.
    - 맵리듀스도 바로 실행이 안되었는데, env 세팅을 설정 파일에 추가함으로써 수정되었다.

- 해당 미션을 하면서 전체적인 도커에 대한 이해도와 하둡에 대한 이해도 및 하둡 노드간에 어떻게 연결되는지 등을 배울 수 있었다.


### W3M2b : 스크립트 이용해서 하둡 설정 변경하기

- **`hadoop.tmp.dir`**
    - 하둡의 중간 계산 결과, 로그, 메타데이터 등을 저장하는 디렉토리
- **`io.file.buffer.size`**
    - 파일 읽기/쓰기 시 사용 되는 버퍼 크기(바이트 단위)
    - 대용량 파일 처리 시 성능향상에 도움
- **`mapreduce.jobhistory.address`**:
    - 완료된 작업의 로그와 기록을 저장하는 서버 주소
- **`mapreduce.task.io.sort.mb`**
    - 맵 태스크 출력 결과를 정렬할 때 사용할 메모리 양
    
- **`yarn.nodemanager.resource.memory-mb`**:
    - 각 NodeManager가 YARN에 할당할 수 있는 총 메모리
    
- **`yarn.scheduler.minimum-allocation-mb`**:
    - 단일 컨테이너에 할당되는 최소 메모리
    - **최적화**: 1GB로 설정하면 작은 작업도 효율적으로 실행된다.


## 회고
### Keep
- 이해되지 않는 부분을 짚고 확실히 이해하기 위해 계속 찾아봐서 다른 상황에서도 활용할 수 있게 노력하고 있다. 지금 당장은 힘들 수 있어도, 한 번 제대로 해두니 다른 상황에 활용할 수 있을 것이다. 실제로 M2a에서 하둡과 도커에 대해 계속 찾아봐서 M2b에서는 비교적 수월하게 진행하고 있는 것 같다.

### Problem
- 아이디어가 명확히 생각나지 않았다. 문제상황을 구체적으로 생각하는 것이 어려운 것 같다. 내가 처해져 있는 상황이 아니기 때문에 디테일 하게 생각하기 어려웠던 것 같고, 이로 인해 좋은 아이디어가 나오지 못했다. 비즈니스 problem을 푸는 과정은 어려운 것 같다.

### Try
- 그 상황에 대입해보고, 내가 그 사람과 같은 경우에 처해있다면 어떨까를 위주로 생각하면서 문제상황을 구체화시켜 봐야겠다. 또 극단적인 가격을 지불하고도 해결하고 싶어하는 문제상황을 찾아봐야겠다.